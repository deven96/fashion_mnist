{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deven96/fashion_mnist/blob/master/Fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M2s8jV-TD2Ze",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "eKTzQamlCHJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bc39194f-2e64-4f20-8e9c-c23a7161527b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pydot\n",
        "import pandas as pd\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the fashion-mnist pre-shuffled train data and test data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vLN0gC4CDtaY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualizing the data"
      ]
    },
    {
      "metadata": {
        "id": "slktfaNcDyWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "37318446-3452-462c-ea0e-65e279bf48e3"
      },
      "cell_type": "code",
      "source": [
        "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Print the number of training and test datasets\n",
        "print(x_train.shape[0], 'train set')\n",
        "print(x_test.shape[0], 'test set')\n",
        "\n",
        "# Define the text labels\n",
        "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
        "                        \"Trouser\",      # index 1\n",
        "                        \"Pullover\",     # index 2 \n",
        "                        \"Dress\",        # index 3 \n",
        "                        \"Coat\",         # index 4\n",
        "                        \"Sandal\",       # index 5\n",
        "                        \"Shirt\",        # index 6 \n",
        "                        \"Sneaker\",      # index 7 \n",
        "                        \"Bag\",          # index 8 \n",
        "                        \"Ankle boot\"]   # index 9\n",
        "\n",
        "# Image index, you can pick any number between 0 and 59,999\n",
        "img_index = 90\n",
        "# y_train contains the lables, ranging from 0 to 9\n",
        "label_index = y_train[img_index]\n",
        "# Print the label, for example 2 Pullover\n",
        "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
        "# # Show one of the images from the training dataset\n",
        "plt.imshow(x_train[img_index])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
            "60000 train set\n",
            "10000 test set\n",
            "y = 9 Ankle boot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdc6e366da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGBAWAKAwX8B8xRJKeyRX9cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdc6e4125f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Z_UtEsphEbWL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Normalization"
      ]
    },
    {
      "metadata": {
        "id": "wTBVuww1Eea9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGI0DLyjEe68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e1275b46-0ac7-42ac-9c17-dfa43efaefec"
      },
      "cell_type": "code",
      "source": [
        "print(\"Number of train data - \" + str(len(x_train)))\n",
        "print(\"Number of test data - \" + str(len(x_test)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train data - 60000\n",
            "Number of test data - 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s0IgyM_oEif8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0f8d68e2-d902-49bc-d8d4-6905289c80bf"
      },
      "cell_type": "code",
      "source": [
        "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "\n",
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Print training set shape\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Print the number of training, validation, and test datasets\n",
        "print(x_train.shape[0], 'train set')\n",
        "print(x_valid.shape[0], 'validation set')\n",
        "print(x_test.shape[0], 'test set')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
            "55000 train set\n",
            "5000 validation set\n",
            "10000 test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rGKbh_jEFR4W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Architecture\n",
        "\n",
        "Tweak CNN parameters to optimize"
      ]
    },
    {
      "metadata": {
        "id": "6ngkgCOqFUuX",
        "colab_type": "code",
        "outputId": "986e8e40-ff34-416c-c5bc-98e7de4ebfe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "cell_type": "code",
      "source": [
        "     \n",
        "\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 241,546\n",
            "Trainable params: 241,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K4OC2NMMYIVY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plot the model"
      ]
    },
    {
      "metadata": {
        "id": "ohOcQ8LZYMPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1249
        },
        "outputId": "624657be-1332-4d56-cc83-0bdbb0705905"
      },
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model.png')\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"921pt\" viewBox=\"0.00 0.00 229.00 921.00\" width=\"229pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 917)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-917 225,-917 225,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140584658424048 -->\n<g class=\"node\" id=\"node1\">\n<title>140584658424048</title>\n<polygon fill=\"none\" points=\"44,-803.5 44,-839.5 177,-839.5 177,-803.5 44,-803.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-817.8\">conv2d_3: Conv2D</text>\n</g>\n<!-- 140584658408952 -->\n<g class=\"node\" id=\"node2\">\n<title>140584658408952</title>\n<polygon fill=\"none\" points=\"0,-730.5 0,-766.5 221,-766.5 221,-730.5 0,-730.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-744.8\">max_pooling2d_2: MaxPooling2D</text>\n</g>\n<!-- 140584658424048&#45;&gt;140584658408952 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140584658424048-&gt;140584658408952</title>\n<path d=\"M110.5,-803.4551C110.5,-795.3828 110.5,-785.6764 110.5,-776.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-776.5903 110.5,-766.5904 107.0001,-776.5904 114.0001,-776.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658554272 -->\n<g class=\"node\" id=\"node3\">\n<title>140584658554272</title>\n<polygon fill=\"none\" points=\"51,-657.5 51,-693.5 170,-693.5 170,-657.5 51,-657.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-671.8\">dropout: Dropout</text>\n</g>\n<!-- 140584658408952&#45;&gt;140584658554272 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140584658408952-&gt;140584658554272</title>\n<path d=\"M110.5,-730.4551C110.5,-722.3828 110.5,-712.6764 110.5,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-703.5903 110.5,-693.5904 107.0001,-703.5904 114.0001,-703.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658554048 -->\n<g class=\"node\" id=\"node4\">\n<title>140584658554048</title>\n<polygon fill=\"none\" points=\"44,-584.5 44,-620.5 177,-620.5 177,-584.5 44,-584.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-598.8\">conv2d_4: Conv2D</text>\n</g>\n<!-- 140584658554272&#45;&gt;140584658554048 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140584658554272-&gt;140584658554048</title>\n<path d=\"M110.5,-657.4551C110.5,-649.3828 110.5,-639.6764 110.5,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-630.5903 110.5,-620.5904 107.0001,-630.5904 114.0001,-630.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658551024 -->\n<g class=\"node\" id=\"node5\">\n<title>140584658551024</title>\n<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 221,-547.5 221,-511.5 0,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-525.8\">max_pooling2d_3: MaxPooling2D</text>\n</g>\n<!-- 140584658554048&#45;&gt;140584658551024 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140584658554048-&gt;140584658551024</title>\n<path d=\"M110.5,-584.4551C110.5,-576.3828 110.5,-566.6764 110.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-557.5903 110.5,-547.5904 107.0001,-557.5904 114.0001,-557.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658553096 -->\n<g class=\"node\" id=\"node6\">\n<title>140584658553096</title>\n<polygon fill=\"none\" points=\"43.5,-438.5 43.5,-474.5 177.5,-474.5 177.5,-438.5 43.5,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-452.8\">dropout_1: Dropout</text>\n</g>\n<!-- 140584658551024&#45;&gt;140584658553096 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140584658551024-&gt;140584658553096</title>\n<path d=\"M110.5,-511.4551C110.5,-503.3828 110.5,-493.6764 110.5,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-484.5903 110.5,-474.5904 107.0001,-484.5904 114.0001,-484.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658868096 -->\n<g class=\"node\" id=\"node7\">\n<title>140584658868096</title>\n<polygon fill=\"none\" points=\"44,-365.5 44,-401.5 177,-401.5 177,-365.5 44,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-379.8\">conv2d_5: Conv2D</text>\n</g>\n<!-- 140584658553096&#45;&gt;140584658868096 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140584658553096-&gt;140584658868096</title>\n<path d=\"M110.5,-438.4551C110.5,-430.3828 110.5,-420.6764 110.5,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-411.5903 110.5,-401.5904 107.0001,-411.5904 114.0001,-411.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658792120 -->\n<g class=\"node\" id=\"node8\">\n<title>140584658792120</title>\n<polygon fill=\"none\" points=\"43.5,-292.5 43.5,-328.5 177.5,-328.5 177.5,-292.5 43.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-306.8\">dropout_2: Dropout</text>\n</g>\n<!-- 140584658868096&#45;&gt;140584658792120 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140584658868096-&gt;140584658792120</title>\n<path d=\"M110.5,-365.4551C110.5,-357.3828 110.5,-347.6764 110.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-338.5903 110.5,-328.5904 107.0001,-338.5904 114.0001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658521896 -->\n<g class=\"node\" id=\"node9\">\n<title>140584658521896</title>\n<polygon fill=\"none\" points=\"54,-219.5 54,-255.5 167,-255.5 167,-219.5 54,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-233.8\">flatten_1: Flatten</text>\n</g>\n<!-- 140584658792120&#45;&gt;140584658521896 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140584658792120-&gt;140584658521896</title>\n<path d=\"M110.5,-292.4551C110.5,-284.3828 110.5,-274.6764 110.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-265.5903 110.5,-255.5904 107.0001,-265.5904 114.0001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658316704 -->\n<g class=\"node\" id=\"node10\">\n<title>140584658316704</title>\n<polygon fill=\"none\" points=\"57,-146.5 57,-182.5 164,-182.5 164,-146.5 57,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-160.8\">dense_2: Dense</text>\n</g>\n<!-- 140584658521896&#45;&gt;140584658316704 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140584658521896-&gt;140584658316704</title>\n<path d=\"M110.5,-219.4551C110.5,-211.3828 110.5,-201.6764 110.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-192.5903 110.5,-182.5904 107.0001,-192.5904 114.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658316928 -->\n<g class=\"node\" id=\"node11\">\n<title>140584658316928</title>\n<polygon fill=\"none\" points=\"43.5,-73.5 43.5,-109.5 177.5,-109.5 177.5,-73.5 43.5,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-87.8\">dropout_3: Dropout</text>\n</g>\n<!-- 140584658316704&#45;&gt;140584658316928 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140584658316704-&gt;140584658316928</title>\n<path d=\"M110.5,-146.4551C110.5,-138.3828 110.5,-128.6764 110.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-119.5903 110.5,-109.5904 107.0001,-119.5904 114.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658316536 -->\n<g class=\"node\" id=\"node12\">\n<title>140584658316536</title>\n<polygon fill=\"none\" points=\"57,-.5 57,-36.5 164,-36.5 164,-.5 57,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 140584658316928&#45;&gt;140584658316536 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140584658316928-&gt;140584658316536</title>\n<path d=\"M110.5,-73.4551C110.5,-65.3828 110.5,-55.6764 110.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-46.5903 110.5,-36.5904 107.0001,-46.5904 114.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140584658554664 -->\n<g class=\"node\" id=\"node13\">\n<title>140584658554664</title>\n<polygon fill=\"none\" points=\"46,-876.5 46,-912.5 175,-912.5 175,-876.5 46,-876.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-890.8\">140584658554664</text>\n</g>\n<!-- 140584658554664&#45;&gt;140584658424048 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140584658554664-&gt;140584658424048</title>\n<path d=\"M110.5,-876.4551C110.5,-868.3828 110.5,-858.6764 110.5,-849.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-849.5903 110.5,-839.5904 107.0001,-849.5904 114.0001,-849.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "MJbhSzR1GGzB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compile the model"
      ]
    },
    {
      "metadata": {
        "id": "BL6X9ncyGJEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtVF2f0RGeSA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "\n",
        "Using the .fit() API"
      ]
    },
    {
      "metadata": {
        "id": "gW3EUnrBGiVf",
        "colab_type": "code",
        "outputId": "476b86bc-8677-43d2-d321-3cbaacd029b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3525
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=128,\n",
        "         epochs=50,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.3421 - acc: 0.8778\n",
            "Epoch 00001: val_loss improved from inf to 0.25074, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 110us/step - loss: 0.3420 - acc: 0.8778 - val_loss: 0.2507 - val_acc: 0.9108\n",
            "Epoch 2/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.3093 - acc: 0.8881\n",
            "Epoch 00002: val_loss improved from 0.25074 to 0.24401, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.3095 - acc: 0.8880 - val_loss: 0.2440 - val_acc: 0.9104\n",
            "Epoch 3/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.2943 - acc: 0.8922\n",
            "Epoch 00003: val_loss improved from 0.24401 to 0.23702, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2944 - acc: 0.8923 - val_loss: 0.2370 - val_acc: 0.9104\n",
            "Epoch 4/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2838 - acc: 0.8955\n",
            "Epoch 00004: val_loss improved from 0.23702 to 0.22605, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2837 - acc: 0.8955 - val_loss: 0.2260 - val_acc: 0.9164\n",
            "Epoch 5/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2728 - acc: 0.8997\n",
            "Epoch 00005: val_loss improved from 0.22605 to 0.22161, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2728 - acc: 0.8997 - val_loss: 0.2216 - val_acc: 0.9170\n",
            "Epoch 6/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.9014\n",
            "Epoch 00006: val_loss did not improve from 0.22161\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2662 - acc: 0.9014 - val_loss: 0.2283 - val_acc: 0.9166\n",
            "Epoch 7/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.2632 - acc: 0.9033\n",
            "Epoch 00007: val_loss did not improve from 0.22161\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2634 - acc: 0.9033 - val_loss: 0.2227 - val_acc: 0.9176\n",
            "Epoch 8/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2535 - acc: 0.9058\n",
            "Epoch 00008: val_loss improved from 0.22161 to 0.22148, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2534 - acc: 0.9059 - val_loss: 0.2215 - val_acc: 0.9162\n",
            "Epoch 9/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2487 - acc: 0.9083\n",
            "Epoch 00009: val_loss improved from 0.22148 to 0.21640, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 108us/step - loss: 0.2486 - acc: 0.9084 - val_loss: 0.2164 - val_acc: 0.9170\n",
            "Epoch 10/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2472 - acc: 0.9068\n",
            "Epoch 00010: val_loss improved from 0.21640 to 0.21279, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2471 - acc: 0.9068 - val_loss: 0.2128 - val_acc: 0.9182\n",
            "Epoch 11/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9107\n",
            "Epoch 00011: val_loss did not improve from 0.21279\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2430 - acc: 0.9107 - val_loss: 0.2132 - val_acc: 0.9240\n",
            "Epoch 12/50\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9123\n",
            "Epoch 00012: val_loss improved from 0.21279 to 0.20791, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2354 - acc: 0.9124 - val_loss: 0.2079 - val_acc: 0.9236\n",
            "Epoch 13/50\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9109\n",
            "Epoch 00013: val_loss improved from 0.20791 to 0.20600, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 108us/step - loss: 0.2358 - acc: 0.9108 - val_loss: 0.2060 - val_acc: 0.9236\n",
            "Epoch 14/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.2296 - acc: 0.9135\n",
            "Epoch 00014: val_loss did not improve from 0.20600\n",
            "55000/55000 [==============================] - 6s 105us/step - loss: 0.2296 - acc: 0.9136 - val_loss: 0.2096 - val_acc: 0.9244\n",
            "Epoch 15/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9134\n",
            "Epoch 00015: val_loss did not improve from 0.20600\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2296 - acc: 0.9133 - val_loss: 0.2115 - val_acc: 0.9236\n",
            "Epoch 16/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9158\n",
            "Epoch 00016: val_loss did not improve from 0.20600\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2225 - acc: 0.9158 - val_loss: 0.2096 - val_acc: 0.9224\n",
            "Epoch 17/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9160\n",
            "Epoch 00017: val_loss did not improve from 0.20600\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2221 - acc: 0.9160 - val_loss: 0.2072 - val_acc: 0.9244\n",
            "Epoch 18/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9164\n",
            "Epoch 00018: val_loss did not improve from 0.20600\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2206 - acc: 0.9164 - val_loss: 0.2064 - val_acc: 0.9284\n",
            "Epoch 19/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9164\n",
            "Epoch 00019: val_loss improved from 0.20600 to 0.20227, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2233 - acc: 0.9164 - val_loss: 0.2023 - val_acc: 0.9254\n",
            "Epoch 20/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2172 - acc: 0.9192\n",
            "Epoch 00020: val_loss did not improve from 0.20227\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2172 - acc: 0.9191 - val_loss: 0.2110 - val_acc: 0.9270\n",
            "Epoch 21/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9181\n",
            "Epoch 00021: val_loss did not improve from 0.20227\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2165 - acc: 0.9181 - val_loss: 0.2069 - val_acc: 0.9250\n",
            "Epoch 22/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9192\n",
            "Epoch 00022: val_loss did not improve from 0.20227\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.2141 - acc: 0.9191 - val_loss: 0.2084 - val_acc: 0.9250\n",
            "Epoch 23/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9194\n",
            "Epoch 00023: val_loss improved from 0.20227 to 0.20147, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 108us/step - loss: 0.2131 - acc: 0.9194 - val_loss: 0.2015 - val_acc: 0.9282\n",
            "Epoch 24/50\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9203\n",
            "Epoch 00024: val_loss did not improve from 0.20147\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2079 - acc: 0.9203 - val_loss: 0.2032 - val_acc: 0.9278\n",
            "Epoch 25/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9220\n",
            "Epoch 00025: val_loss improved from 0.20147 to 0.19697, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2078 - acc: 0.9220 - val_loss: 0.1970 - val_acc: 0.9276\n",
            "Epoch 26/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2075 - acc: 0.9212\n",
            "Epoch 00026: val_loss did not improve from 0.19697\n",
            "55000/55000 [==============================] - 6s 105us/step - loss: 0.2074 - acc: 0.9213 - val_loss: 0.1982 - val_acc: 0.9292\n",
            "Epoch 27/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9240\n",
            "Epoch 00027: val_loss did not improve from 0.19697\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2044 - acc: 0.9239 - val_loss: 0.2014 - val_acc: 0.9278\n",
            "Epoch 28/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9213\n",
            "Epoch 00028: val_loss improved from 0.19697 to 0.19517, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2061 - acc: 0.9213 - val_loss: 0.1952 - val_acc: 0.9288\n",
            "Epoch 29/50\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9234\n",
            "Epoch 00029: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.2015 - acc: 0.9235 - val_loss: 0.2014 - val_acc: 0.9264\n",
            "Epoch 30/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9248\n",
            "Epoch 00030: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 105us/step - loss: 0.2003 - acc: 0.9248 - val_loss: 0.2040 - val_acc: 0.9286\n",
            "Epoch 31/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.2012 - acc: 0.9239\n",
            "Epoch 00031: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 105us/step - loss: 0.2016 - acc: 0.9237 - val_loss: 0.2065 - val_acc: 0.9244\n",
            "Epoch 32/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9263\n",
            "Epoch 00032: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.1983 - acc: 0.9261 - val_loss: 0.1971 - val_acc: 0.9286\n",
            "Epoch 33/50\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9256\n",
            "Epoch 00033: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.1976 - acc: 0.9257 - val_loss: 0.2029 - val_acc: 0.9278\n",
            "Epoch 34/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9250\n",
            "Epoch 00034: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.1982 - acc: 0.9249 - val_loss: 0.1974 - val_acc: 0.9274\n",
            "Epoch 35/50\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9273\n",
            "Epoch 00035: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.1950 - acc: 0.9273 - val_loss: 0.2071 - val_acc: 0.9266\n",
            "Epoch 36/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9278\n",
            "Epoch 00036: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 105us/step - loss: 0.1905 - acc: 0.9278 - val_loss: 0.1964 - val_acc: 0.9270\n",
            "Epoch 37/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9262\n",
            "Epoch 00037: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.1936 - acc: 0.9263 - val_loss: 0.2054 - val_acc: 0.9270\n",
            "Epoch 38/50\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9253\n",
            "Epoch 00038: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.1946 - acc: 0.9252 - val_loss: 0.1997 - val_acc: 0.9268\n",
            "Epoch 39/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.1894 - acc: 0.9281\n",
            "Epoch 00039: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.1894 - acc: 0.9282 - val_loss: 0.2019 - val_acc: 0.9280\n",
            "Epoch 40/50\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.1896 - acc: 0.9276\n",
            "Epoch 00040: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 108us/step - loss: 0.1896 - acc: 0.9275 - val_loss: 0.1963 - val_acc: 0.9284\n",
            "Epoch 41/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9269\n",
            "Epoch 00041: val_loss improved from 0.19517 to 0.19517, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.1932 - acc: 0.9269 - val_loss: 0.1952 - val_acc: 0.9286\n",
            "Epoch 42/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9283\n",
            "Epoch 00042: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.1896 - acc: 0.9283 - val_loss: 0.1979 - val_acc: 0.9304\n",
            "Epoch 43/50\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9293\n",
            "Epoch 00043: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 105us/step - loss: 0.1852 - acc: 0.9293 - val_loss: 0.2027 - val_acc: 0.9232\n",
            "Epoch 44/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.1870 - acc: 0.9296\n",
            "Epoch 00044: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.1869 - acc: 0.9296 - val_loss: 0.1974 - val_acc: 0.9296\n",
            "Epoch 45/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9307\n",
            "Epoch 00045: val_loss did not improve from 0.19517\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.1854 - acc: 0.9307 - val_loss: 0.1985 - val_acc: 0.9262\n",
            "Epoch 46/50\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9297\n",
            "Epoch 00046: val_loss improved from 0.19517 to 0.19487, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 108us/step - loss: 0.1861 - acc: 0.9296 - val_loss: 0.1949 - val_acc: 0.9286\n",
            "Epoch 47/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9296\n",
            "Epoch 00047: val_loss did not improve from 0.19487\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.1851 - acc: 0.9296 - val_loss: 0.2047 - val_acc: 0.9268\n",
            "Epoch 48/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9294\n",
            "Epoch 00048: val_loss did not improve from 0.19487\n",
            "55000/55000 [==============================] - 6s 109us/step - loss: 0.1854 - acc: 0.9295 - val_loss: 0.2069 - val_acc: 0.9258\n",
            "Epoch 49/50\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9306\n",
            "Epoch 00049: val_loss improved from 0.19487 to 0.19197, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 6s 107us/step - loss: 0.1831 - acc: 0.9307 - val_loss: 0.1920 - val_acc: 0.9286\n",
            "Epoch 50/50\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9313\n",
            "Epoch 00050: val_loss did not improve from 0.19197\n",
            "55000/55000 [==============================] - 6s 106us/step - loss: 0.1819 - acc: 0.9312 - val_loss: 0.1944 - val_acc: 0.9298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc6a22eb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "LtQuJrHFIynV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save trained model"
      ]
    },
    {
      "metadata": {
        "id": "CMEoDs-LCE6J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooWlvpjkGi4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47c66039-b435-4af9-d1f3-fd88bdf76d62"
      },
      "cell_type": "code",
      "source": [
        "#load best weight and save to drive\n",
        "model.load_weights('model.weights.best.hdf5')\n",
        "model.save('fashion_mnist_trained.h5')\n",
        "model_file = drive.CreateFile({'title' : 'fashion_mnist_trained.h5'})\n",
        "model_file.SetContentFile('fashion_mnist_trained.h5')\n",
        "model_file.Upload()\n",
        "\n",
        "# download to google drive\n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '1q0H8v_O9TWb-scwbKCmvm6QFAPXkgzQf'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "9JEr6kgSwO3B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict values"
      ]
    },
    {
      "metadata": {
        "id": "shSbqIrFwQ0S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(x_test)\n",
        "\n",
        "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
        "figure = plt.figure(figsize=(20, 8))\n",
        "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
        "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
        "    # Display each image\n",
        "    ax.imshow(np.squeeze(x_test[index]))\n",
        "    predict_index = np.argmax(y_hat[index])\n",
        "    true_index = np.argmax(y_test[index])\n",
        "    print(true_index)\n",
        "    # Set the title for each image\n",
        "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
        "                                  fashion_mnist_labels[true_index]),\n",
        "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ax4as_pbwR2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}